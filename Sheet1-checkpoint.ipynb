{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6699bf7d",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199108ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "train_data_loader = DataLoader(training_data, batch_size=64)\n",
    "test_data_loader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "\n",
    "# Relu network\n",
    "class NeuralNetworkRelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkRelu, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "# Selu network\n",
    "class NeuralNetworkSelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkSelu, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_selu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 10),)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_selu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "# sigmoid network\n",
    "class NeuralNetworkSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkSigmoid, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_sigmoid_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 10),)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_sigmoid_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3518acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data_loader, model, loss_function, optimizer):\n",
    "    for batch, (data, labels) in enumerate(data_loader):\n",
    "        # Feed data through network and compute loss.\n",
    "        prediction = model(data)\n",
    "        loss = loss_function(prediction, labels)\n",
    " \n",
    "        # Zero gradients.\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # Perform backpropagation and accumulate gradients.\n",
    "        loss.backward()\n",
    " \n",
    "        # Update network parameters.\n",
    "        optimizer.step()\n",
    " \n",
    " \n",
    "def test_loop(data_loader, model, loss_function):\n",
    "    n_samples = len(data_loader.dataset)\n",
    "    n_batches = len(data_loader)\n",
    "    loss, n_correct = 0, 0\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            # Feed data through network and accumulate loss.\n",
    "            prediction = model(data)\n",
    "            loss += loss_function(prediction, labels).item()\n",
    "            n_correct += ((prediction.argmax(1) == labels).type(torch.float).sum().item())\n",
    " \n",
    "    print(f\"Test Accuracy: {n_correct / n_samples:.2%}, \"f\"Test Loss: {loss / n_batches:.4}\")\n",
    "    return (round((n_correct / n_samples),3), round((loss / n_batches),3))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41488a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Test Accuracy: 47.20%, Test Loss: 2.134\n",
      "Epoch 02 Test Accuracy: 57.65%, Test Loss: 1.842\n",
      "Epoch 03 Test Accuracy: 61.81%, Test Loss: 1.484\n",
      "Epoch 04 Test Accuracy: 63.72%, Test Loss: 1.238\n",
      "Epoch 05 Test Accuracy: 64.96%, Test Loss: 1.082\n",
      "Epoch 06 Test Accuracy: 66.01%, Test Loss: 0.9792\n",
      "Epoch 07 Test Accuracy: 67.12%, Test Loss: 0.9079\n",
      "Epoch 08 Test Accuracy: 68.45%, Test Loss: 0.856\n",
      "Epoch 09 Test Accuracy: 69.78%, Test Loss: 0.8165\n",
      "Epoch 10 Test Accuracy: 71.25%, Test Loss: 0.7851\n"
     ]
    }
   ],
   "source": [
    "model_relu = NeuralNetworkRelu()\n",
    "acc_dict_relu = {}\n",
    "loss_dict_relu = {}\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model_relu.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the network.\n",
    "n_epochs = 10\n",
    "for t in range(n_epochs):\n",
    "    print(f\"Epoch {t + 1:02}\", end=\" \", flush=True)\n",
    "    train_loop(train_data_loader, model_relu, loss_fn, optimizer)\n",
    "    acc, loss = test_loop(test_data_loader, model_relu, loss_fn)\n",
    "    acc_dict_relu[t] = acc\n",
    "    loss_dict_relu[t] = loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4cb442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.472, 0.577, 0.618, 0.637, 0.65, 0.66, 0.671, 0.684, 0.698, 0.713])\n",
      "dict_values([2.134, 1.842, 1.484, 1.238, 1.082, 0.979, 0.908, 0.856, 0.817, 0.785])\n"
     ]
    }
   ],
   "source": [
    "print(acc_dict_relu.values())\n",
    "print(loss_dict_relu.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7f5cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Test Accuracy: 64.93%, Test Loss: 1.318\n",
      "Epoch 02 Test Accuracy: 67.65%, Test Loss: 0.9871\n",
      "Epoch 03 Test Accuracy: 70.77%, Test Loss: 0.8509\n",
      "Epoch 04 Test Accuracy: 73.24%, Test Loss: 0.7737\n",
      "Epoch 05 Test Accuracy: 74.89%, Test Loss: 0.7212\n",
      "Epoch 06 Test Accuracy: 76.25%, Test Loss: 0.6818\n",
      "Epoch 07 Test Accuracy: 77.38%, Test Loss: 0.6508\n",
      "Epoch 08 Test Accuracy: 78.20%, Test Loss: 0.6256\n",
      "Epoch 09 Test Accuracy: 79.05%, Test Loss: 0.6049\n",
      "Epoch 10 Test Accuracy: 79.66%, Test Loss: 0.5877\n"
     ]
    }
   ],
   "source": [
    "model_selu = NeuralNetworkSelu()\n",
    "\n",
    "acc_dict_selu = {}\n",
    "loss_dict_selu = {}\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model_selu.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the network.\n",
    "n_epochs = 10\n",
    "for t in range(n_epochs):\n",
    "    print(f\"Epoch {t + 1:02}\", end=\" \", flush=True)\n",
    "    train_loop(train_data_loader, model_selu, loss_fn, optimizer)\n",
    "    acc, loss = test_loop(test_data_loader, model_selu, loss_fn)\n",
    "    acc_dict_selu[t] = acc\n",
    "    loss_dict_selu[t] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6fe21fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.649, 0.676, 0.708, 0.732, 0.749, 0.762, 0.774, 0.782, 0.79, 0.797])\n",
      "dict_values([1.318, 0.987, 0.851, 0.774, 0.721, 0.682, 0.651, 0.626, 0.605, 0.588])\n"
     ]
    }
   ],
   "source": [
    "print(acc_dict_selu.values())\n",
    "print(loss_dict_selu.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3472b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Test Accuracy: 10.00%, Test Loss: 2.301\n",
      "Epoch 02 Test Accuracy: 10.00%, Test Loss: 2.299\n",
      "Epoch 03 Test Accuracy: 10.00%, Test Loss: 2.296\n",
      "Epoch 04 Test Accuracy: 10.00%, Test Loss: 2.294\n",
      "Epoch 05 Test Accuracy: 10.00%, Test Loss: 2.292\n",
      "Epoch 06 Test Accuracy: 11.28%, Test Loss: 2.289\n",
      "Epoch 07 Test Accuracy: 18.73%, Test Loss: 2.286\n",
      "Epoch 08 Test Accuracy: 23.27%, Test Loss: 2.283\n",
      "Epoch 09 Test Accuracy: 25.08%, Test Loss: 2.28\n",
      "Epoch 10 Test Accuracy: 25.99%, Test Loss: 2.276\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = NeuralNetworkSigmoid()\n",
    "\n",
    "acc_dict_sigmoid = {}\n",
    "loss_dict_sigmoid = {}\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model_sigmoid.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the network.\n",
    "n_epochs = 10\n",
    "for t in range(n_epochs):\n",
    "    print(f\"Epoch {t + 1:02}\", end=\" \", flush=True)\n",
    "    train_loop(train_data_loader, model_sigmoid, loss_fn, optimizer)\n",
    "    acc, loss = test_loop(test_data_loader, model_sigmoid, loss_fn)\n",
    "    acc_dict_sigmoid[t] = acc\n",
    "    loss_dict_sigmoid[t] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd041f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.1, 0.1, 0.1, 0.1, 0.1, 0.113, 0.187, 0.233, 0.251, 0.26])\n",
      "dict_values([2.301, 2.299, 2.296, 2.294, 2.292, 2.289, 2.286, 2.283, 2.28, 2.276])\n"
     ]
    }
   ],
   "source": [
    "print(acc_dict_sigmoid.values())\n",
    "print(loss_dict_sigmoid.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb7744",
   "metadata": {},
   "source": [
    "Exercise 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323cd2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Test Accuracy: 83.61%, Test Loss: 0.4403\n",
      "Epoch 02 Test Accuracy: 85.87%, Test Loss: 0.3927\n",
      "Epoch 03 Test Accuracy: 87.12%, Test Loss: 0.3663\n",
      "Epoch 04 Test Accuracy: 86.51%, Test Loss: 0.3868\n",
      "Epoch 05 Test Accuracy: 86.92%, Test Loss: 0.3808\n",
      "Epoch 06 Test Accuracy: 86.73%, Test Loss: 0.4132\n",
      "Epoch 07 Test Accuracy: 87.07%, Test Loss: 0.4002\n",
      "Epoch 08 Test Accuracy: 87.80%, Test Loss: 0.4246\n",
      "Epoch 09 Test Accuracy: 87.45%, Test Loss: 0.4262\n",
      "Epoch 10 Test Accuracy: 87.94%, Test Loss: 0.4104\n",
      "accuracies and losses for batchsize 10\n",
      "[0.836, 0.859, 0.871, 0.865, 0.869, 0.867, 0.871, 0.878, 0.875, 0.879]\n",
      "[0.44, 0.393, 0.366, 0.387, 0.381, 0.413, 0.4, 0.425, 0.426, 0.41]\n",
      "Epoch 01 Test Accuracy: 85.01%, Test Loss: 0.4134\n",
      "Epoch 02 Test Accuracy: 85.53%, Test Loss: 0.3965\n",
      "Epoch 03 Test Accuracy: 86.48%, Test Loss: 0.3762\n",
      "Epoch 04 Test Accuracy: 87.24%, Test Loss: 0.3613\n",
      "Epoch 05 Test Accuracy: 86.76%, Test Loss: 0.3904\n",
      "Epoch 06 Test Accuracy: 87.65%, Test Loss: 0.3633\n",
      "Epoch 07 Test Accuracy: 87.74%, Test Loss: 0.3876\n",
      "Epoch 08 Test Accuracy: 87.67%, Test Loss: 0.4091\n",
      "Epoch 09 Test Accuracy: 87.65%, Test Loss: 0.3939\n",
      "Epoch 10 Test Accuracy: 87.95%, Test Loss: 0.3932\n",
      "accuracies and losses for batchsize 20\n",
      "[0.85, 0.855, 0.865, 0.872, 0.868, 0.876, 0.877, 0.877, 0.876, 0.879]\n",
      "[0.413, 0.397, 0.376, 0.361, 0.39, 0.363, 0.388, 0.409, 0.394, 0.393]\n",
      "Epoch 01 Test Accuracy: 84.26%, Test Loss: 0.4154\n",
      "Epoch 02 Test Accuracy: 86.42%, Test Loss: 0.3716\n",
      "Epoch 03 Test Accuracy: 87.47%, Test Loss: 0.3464\n",
      "Epoch 04 Test Accuracy: 87.67%, Test Loss: 0.3474\n",
      "Epoch 05 Test Accuracy: 87.74%, Test Loss: 0.3452\n",
      "Epoch 06 Test Accuracy: 87.78%, Test Loss: 0.3452\n",
      "Epoch 07 Test Accuracy: 87.83%, Test Loss: 0.36\n",
      "Epoch 08 Test Accuracy: 88.02%, Test Loss: 0.359\n",
      "Epoch 09 Test Accuracy: 87.88%, Test Loss: 0.4021\n",
      "Epoch 10 Test Accuracy: 88.06%, Test Loss: 0.3884\n",
      "accuracies and losses for batchsize 30\n",
      "[0.843, 0.864, 0.875, 0.877, 0.877, 0.878, 0.878, 0.88, 0.879, 0.881]\n",
      "[0.415, 0.372, 0.346, 0.347, 0.345, 0.345, 0.36, 0.359, 0.402, 0.388]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [10,20,30]\n",
    "\n",
    "for batch_size in batch_sizes: \n",
    "    \n",
    "    # data loader with varying batch-size\n",
    "    train_data_loader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    model_relu = NeuralNetworkRelu()\n",
    "    \n",
    "    accuracies = []\n",
    "    losses = []\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    learning_rate = 1e-3\n",
    "    optimizer = torch.optim.Adam(model_relu.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the network.\n",
    "    n_epochs = 10\n",
    "    for t in range(n_epochs):\n",
    "        print(f\"Epoch {t + 1:02}\", end=\" \", flush=True)\n",
    "        train_loop(train_data_loader, model_relu, loss_fn, optimizer)\n",
    "        acc, loss = test_loop(test_data_loader, model_relu, loss_fn)\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss)\n",
    "\n",
    "    print(\"accuracies and losses for batchsize \" + str(batch_size))\n",
    "    print(accuracies)\n",
    "    print(losses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd2816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
